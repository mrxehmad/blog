<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <title>Ehmi</title>
    <link href="https://blog.ehmad.site/feed.xml" rel="self" />
    <link href="https://blog.ehmad.site" />
    <updated>2025-03-09T16:48:30+05:00</updated>
    <author>
        <name>Ehmad</name>
    </author>
    <id>https://blog.ehmad.site</id>

    <entry>
        <title>Follow-Up: Solution for SSL Error &quot;ERR_SSL_UNRECOGNIZED_NAME_ALERT&quot; in Local</title>
        <author>
            <name>Ehmad</name>
        </author>
        <link href="https://blog.ehmad.site/follow-up-solution-for-ssl-error-err_ssl_unrecognized_name_alert-in-local/"/>
        <id>https://blog.ehmad.site/follow-up-solution-for-ssl-error-err_ssl_unrecognized_name_alert-in-local/</id>

        <updated>2025-03-09T16:47:39+05:00</updated>
            <summary>
                <![CDATA[
                    SSL Error “ERR_SSL_UNRECOGNIZED_NAME_ALERT” in Local Networks Using Cloudflare Tunnels In a previous article, I discussed the issue of intermittent SSL errors when using Cloudflare tunnels in local networks and explored possible solutions. However, the methods suggested did not completely resolve the issue. Thanks to a&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h3 id="ssl-error-err_ssl_unrecognized_name_alert-------------in-local-networks-using-cloudflare-tunnels">SSL Error “ERR_SSL_UNRECOGNIZED_NAME_ALERT”             in Local Networks Using Cloudflare Tunnels</h3>
<p>In a previous article, I discussed the issue of intermittent SSL errors when using Cloudflare tunnels in local networks and explored possible solutions. However, the methods suggested did not completely resolve the issue. Thanks to a detailed analysis and solution provided by <a href="https://github.com/dasunsrule32">@dasunsrule32</a> on a <a href="https://github.com/NginxProxyManager/nginx-proxy-manager/issues/3982#issuecomment-2408597306">GitHub issue</a>, we now have a much better fix that ensures seamless connectivity without breaking HTTPS queries.</p><h2 id="understanding-the-root-cause"><strong>Understanding the Root Cause</strong></h2>
<p>The issue stems from modern browsers prioritizing <code>HTTPS</code> records with <code>ipv4hint</code> and <code>ipv6hint</code> when resolving domains. These records, deployed by Cloudflare, Google, and other major providers, speed up DNS resolution but can cause conflicts in local networks when using Pi-hole or custom DNS configurations.</p><p>Previously, many users (myself included) attempted workarounds like disabling IPv6, modifying local DNS configurations, or relying on the default Pi-hole settings. However, these solutions were either incomplete or required manual intervention on client devices.</p><h2 id="the-improved-solution"><strong>The Improved Solution</strong></h2>
<p><a href="https://github.com/dasunsrule32">@dasunsrule32</a> provided a better approach that ensures Pi-hole properly handles these HTTPS record queries without breaking other services. The key fix is to <strong>block <code>HTTPS</code> record lookups for specific domains while keeping normal DNS functionality intact.</strong></p><h3 id="implementation-steps-in-pi-hole"><strong>Implementation Steps in Pi-hole</strong></h3>
<ol>
<li><strong>Create a custom DNS configuration file</strong> for Pi-hole:<pre><code class="language-sh">sudo nano /etc/dnsmasq.d/02-custom-dns.conf
</code></pre>
</li>
</ol>
<p>(Optional) maybe, becouse it didn’t work for me. Maybe works for you, Please let me know if it works. </p><ol start="2">
<li><p><strong>Add the following line to force Pi-hole to resolve the domain locally:</strong></p><pre><code>address=/pihole.domain.com/10.1.15.103
</code></pre>
<p>This ensures that <code>pihole.domain.com</code> resolves correctly within the network.</p></li>
<li><p><strong>Block HTTPS record queries for subdomains of <code>domain.com</code></strong> using a regex filter:</p><p>Open the Pi-hole web interface and go to <strong>Domains</strong>, then add the following regex filter:</p><pre><code>^.*\.domain\.com$;querytype=HTTPS
</code></pre>
<p>This prevents browsers from prioritizing Cloudflare’s <code>HTTPS</code> records while allowing normal A/AAAA queries.</p></li>
<li><p><strong>Restart Pi-hole to apply the changes:</strong></p><pre><code class="language-sh">pihole restartdns
</code></pre>
</li>
</ol>
<h2 id="verifying-the-fix"><strong>Verifying the Fix</strong></h2>
<p>To ensure the changes are working, you can use <code>dig</code> to check whether Pi-hole is correctly handling DNS requests:</p><pre><code class="language-sh">dig HTTPS pihole.domain.com @10.1.15.103
</code></pre>
<p>If the output no longer contains an <code>HTTPS</code> record response, the fix is correctly applied.</p><h2 id="final-thoughts"><strong>Final Thoughts</strong></h2>
<p>This solution effectively prevents SSL errors without requiring changes on client devices. Unlike previous workarounds, it ensures that local DNS remains functional while overriding problematic <code>HTTPS</code> records. Huge thanks to <a href="https://github.com/dasunsrule32">@dasunsrule32</a> for their detailed debugging and contribution to the solution.</p><p>If you previously struggled with SSL errors in Cloudflare tunnels, I highly recommend implementing this fix. For further discussion or improvements, check out the <a href="https://github.com/NginxProxyManager/nginx-proxy-manager/issues/3982#issuecomment-2408597306">GitHub issue thread</a>. Let me know in the comments if you have any questions or additional insights!</p><hr>
<h3 id="related-reading"><strong>Related Reading:</strong></h3>
<ul>
<li><a href="https://blog.ehmad.site/how-to-fix-intermittent-ssl-errors-in-local-networks-when-using-cloudflare-tunnels/">My Previous Article on Fixing Intermittent SSL Errors</a></li>
</ul>

            ]]>
        </content>
    </entry>
    <entry>
        <title>How to Fix Intermittent SSL Errors in Local Networks When Using Cloudflare Tunnels Not Working :/ </title>
        <author>
            <name>Ehmad</name>
        </author>
        <link href="https://blog.ehmad.site/how-to-fix-intermittent-ssl-errors-in-local-networks-when-using-cloudflare-tunnels/"/>
        <id>https://blog.ehmad.site/how-to-fix-intermittent-ssl-errors-in-local-networks-when-using-cloudflare-tunnels/</id>

        <updated>2025-03-08T17:57:57+05:00</updated>
            <summary>
                <![CDATA[
                    If you’re hosting a service on your local network and using Cloudflare tunnels for external access, you might encounter intermittent SSL errors like ssl_error_unrecognized_name_alert when accessing your site locally. This issue arises due to DNS resolution inconsistencies or certificate mismatches between your local server and&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>If you’re hosting a service on your local network and using Cloudflare tunnels for external access, you might encounter intermittent SSL errors like <code>ssl_error_unrecognized_name_alert</code> when accessing your site locally. This issue arises due to DNS resolution inconsistencies or certificate mismatches between your local server and Cloudflare’s CDN. In this article, we’ll explore the root cause of the problem and provide a comprehensive solution. This journey made me cry fr.</p><hr>
<h2 id="the-problem-why-does-this-happen"><strong>The Problem: Why Does This Happen?</strong></h2>
<p>When you host a service (e.g., a website) on your local network and use Cloudflare tunnels for external access, there are two distinct paths for traffic:</p><ol>
<li><p><strong>Local Network Traffic</strong>:</p><ul>
<li>Clients within the local network should resolve the domain (e.g., <code>pihole.example.com</code>) to the internal IP address of your server (e.g., <code>192.168.1.100</code>).</li>
<li>The local server serves an SSL certificate issued by Let’s Encrypt for <code>*.example.com</code>.</li>
</ul>
</li>
<li><p><strong>External Network Traffic</strong>:</p><ul>
<li>Clients outside the local network resolve the domain to Cloudflare’s external IP (e.g., <code>104.x.x.x</code>).</li>
<li>Cloudflare serves its own SSL certificate for <code>example.com</code>.</li>
</ul>
</li>
</ol>
<h3 id="why-do-ssl-errors-occur-locally"><strong>Why Do SSL Errors Occur Locally?</strong></h3>
<ul>
<li><strong>DNS Resolution Fluctuations</strong>: If your local DNS resolver (e.g., Pi-hole) intermittently resolves the domain to the external IP instead of the internal IP, the request routes through Cloudflare. Cloudflare’s certificate does not match the subdomain (<code>pihole.example.com</code>), causing an SSL error.</li>
<li><strong>SNI Misconfiguration</strong>: Some clients or devices may not send the correct Server Name Indication (SNI) header, leading the server to default to an incorrect certificate.</li>
</ul>
<hr>
<h2 id="solution-how-to-fix-the-issue"><strong>Solution: How to Fix the Issue</strong></h2>
<p>To resolve the problem, you need to ensure consistent DNS resolution and proper SSL certificate handling for local clients. Follow these steps:</p><hr>
<h3 id="step-1-configure-split-horizon-dns-in-pi-hole"><strong>Step 1: Configure Split-Horizon DNS in Pi-hole</strong></h3>
<p>Split-horizon DNS ensures that local clients resolve the domain to the internal IP address while external clients resolve it to the external IP.</p><ol>
<li><p><strong>Add Local DNS Records</strong>:</p><ul>
<li>Go to <strong>Pi-hole &gt; Local DNS &gt; DNS Records</strong>.</li>
<li>Add a wildcard entry for your domain:<pre><code>Domain: *.example.com
IP: 192.168.1.100
</code></pre>
</li>
<li>Save the configuration.</li>
</ul>
</li>
<li><p><strong>Disable Upstream Forwarding</strong>:</p><ul>
<li>Navigate to <strong>Pi-hole &gt; Settings &gt; DNS</strong>.</li>
<li>Under <strong>“Never forward the following domains”</strong>, add:<pre><code>example.com
</code></pre>
</li>
<li>Save the settings to prevent Pi-hole from querying external DNS servers for this domain.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="step-2-verify-web-server-configuration"><strong>Step 2: Verify Web Server Configuration</strong></h3>
<p>Ensure your web server (e.g., Nginx or Apache) is properly configured to handle requests for the subdomain (<code>pihole.example.com</code>).</p><h4 id="for-nginx"><strong>For Nginx</strong>:</h4>
<pre><code class="language-nginx">server {
    listen 443 ssl;
    server_name pihole.example.com;

    ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;

    # Other SSL settings...
}
</code></pre>
<h4 id="for-apache"><strong>For Apache</strong>:</h4>
<pre><code class="language-apache">&lt;VirtualHost *:443&gt;
    ServerName pihole.example.com

    SSLEngine on
    SSLCertificateFile /etc/letsencrypt/live/example.com/fullchain.pem
    SSLCertificateKeyFile /etc/letsencrypt/live/example.com/privkey.pem

    # Other SSL settings...
&lt;/VirtualHost&gt;
</code></pre>
<hr>
<h3 id="step-3-test-dns-resolution"><strong>Step 3: Test DNS Resolution</strong></h3>
<p>After configuring Pi-hole, verify that the domain resolves correctly to the internal IP:</p><pre><code class="language-bash">nslookup pihole.example.com 192.168.1.100
</code></pre>
<p>The output should return:</p><pre><code>Address: 192.168.1.100
</code></pre>
<p>If it returns the external IP (e.g., <code>104.21.50.106</code>), revisit your Pi-hole configuration to ensure split-horizon DNS is working as expected.</p><hr>
<h3 id="step-4-clear-client-side-caches"><strong>Step 4: Clear Client-Side Caches</strong></h3>
<p>Sometimes, old DNS records or browser caches can cause issues. Clear them as follows:</p><h4 id="clear-dns-cache"><strong>Clear DNS Cache</strong>:</h4>
<pre><code class="language-bash"># Windows
ipconfig /flushdns

# Linux/macOS
sudo systemd-resolve --flush-caches
</code></pre>
<h4 id="clear-browser-cache"><strong>Clear Browser Cache</strong>:</h4>
<p>Use incognito mode or manually clear your browser’s cache.</p><hr>
<h3 id="step-5-test-ssl-handshake"><strong>Step 5: Test SSL Handshake</strong></h3>
<p>Finally, test the SSL handshake to confirm that the correct certificate is being served:</p><pre><code class="language-bash">openssl s_client -connect 192.168.1.100:443 -servername pihole.example.com
</code></pre>
<p>Look for the following in the output:</p><ul>
<li><strong>Subject</strong>: <code>CN = *.example.com</code></li>
<li><strong>Issuer</strong>: <code>C = US, O = Let&#39;s Encrypt, CN = E6</code></li>
</ul>
<p>If the certificate matches, your setup is correct.</p><hr>
<p>Yes, that’s correct! If you’re using Cloudflare for external access and also want to serve your domains locally within your network, it’s important to ensure that <strong>all domains managed by Cloudflare</strong> (including the main domain and its subdomains) are properly forwarded to your local server and have valid SSL certificates issued by Let’s Encrypt. This ensures consistent behavior for both local and external traffic.</p><p>Here’s a detailed explanation of why this is necessary and how to implement it:</p><hr>
<h2 id="why-should-all-domains-managed-by-cloudflare-be-forwarded-locally"><strong>Why Should All Domains Managed by Cloudflare Be Forwarded Locally?</strong></h2>
<ol>
<li><p><strong>Consistent DNS Resolution</strong>:</p><ul>
<li>When a domain or subdomain is managed by Cloudflare, external clients resolve it to Cloudflare’s IP addresses. However, local clients should resolve it to your internal server’s IP address (e.g., <code>192.168.1.100</code>).</li>
<li>Without proper local DNS forwarding, local clients might inadvertently resolve the domain to Cloudflare’s external IP, causing SSL mismatches or routing issues.</li>
</ul>
</li>
<li><p><strong>Avoid Certificate Mismatches</strong>:</p><ul>
<li>Cloudflare serves its own SSL certificate for domains it manages. If a local client resolves a domain to Cloudflare’s external IP, the certificate presented will not match the local server’s configuration.</li>
<li>By forwarding all domains locally and using Let’s Encrypt certificates on your local server, you ensure that local clients always receive the correct certificate.</li>
</ul>
</li>
<li><p><strong>Performance and Reliability</strong>:</p><ul>
<li>Routing local traffic through Cloudflare introduces unnecessary latency and dependency on external services. By resolving domains locally, you improve performance and reduce reliance on external infrastructure.</li>
</ul>
</li>
</ol>
<hr>
<h2 id="forward-main-domain-and-sub-domain-locally-and-secure-them-with-lets-encrypt"><strong>Forward Main Domain and Sub Domain Locally and Secure Them with Let’s Encrypt</strong></h2>
<h3 id="step-1-add-local-dns-records-for-all-domains"><strong>Step 1: Add Local DNS Records for All Domains</strong></h3>
<p>In Pi-hole, configure split-horizon DNS to ensure all domains and subdomains resolve to your local server’s IP address.</p><ol>
<li><p>Go to <strong>Pi-hole &gt; Local DNS &gt; DNS Records</strong>.</p></li>
<li><p>Add entries for your main domain and subdomains:</p><pre><code>Domain: example.com
IP: 192.168.1.100

Domain: *.example.com
IP: 192.168.1.100
</code></pre>
<ul>
<li>The wildcard entry (<code>*.example.com</code>) ensures that all subdomains (e.g., <code>pihole.example.com</code>, <code>www.example.com</code>) resolve locally.(pihle local dns doens’t support wildcards. You have to add each domain manually )</li>
</ul>
</li>
<li><p>Save the configuration.</p></li>
</ol>
<hr>
<h3 id="step-2-disable-upstream-forwarding-for-all-domains-optional"><strong>Step 2: Disable Upstream Forwarding for All Domains (Optional)</strong></h3>
<p>Prevent Pi-hole from querying external DNS servers for your domains.</p><ol>
<li>Navigate to <strong>Pi-hole &gt; Domains</strong>.</li>
<li>Under <strong>“Add Wildcard Regex blocklist”</strong>, add:<pre><code>*.example.com
</code></pre>
</li>
<li>Save the settings.</li>
</ol>
<hr>
<h3 id="step-3-obtain-lets-encrypt-certificates-for-all-domains-google-it-if-you-dont-have"><strong>Step 3: Obtain Let’s Encrypt Certificates for All Domains (Google it if you don’t have)</strong></h3>
<h3 id="step-4-test-your-configuration"><strong>Step 4: Test Your Configuration</strong></h3>
<p>After setting up DNS and SSL, test the following:</p><ol>
<li><p><strong>DNS Resolution</strong>:</p><pre><code class="language-bash">nslookup example.com 192.168.1.100
nslookup pihole.example.com 192.168.1.100
</code></pre>
<ul>
<li>Both should return <code>192.168.1.100</code>.</li>
</ul>
</li>
<li><p><strong>SSL Handshake</strong>:</p><pre><code class="language-bash">openssl s_client -connect 192.168.1.100:443 -servername pihole.example.com
</code></pre>
<ul>
<li>Verify that the certificate matches <code>*.example.com</code>.</li>
</ul>
</li>
<li><p><strong>Browser Access</strong>:</p><ul>
<li>Open <code>https://pihole.example.com</code> in a browser and confirm that the site loads without SSL errors.</li>
</ul>
</li>
</ol>
<hr>
<h2 id="key-points-to-remember"><strong>Key Points to Remember</strong></h2>
<ol>
<li><p><strong>All Domains Must Resolve Locally</strong>:</p><ul>
<li>Ensure that both the main domain (<code>example.com</code>) and all subdomains  resolve to your local server’s IP address.</li>
</ul>
</li>
<li><p><strong>Use Let’s Encrypt for Local SSL</strong>:</p><ul>
<li>Let’s Encrypt certificates are free, widely trusted, and easy to renew. They ensure that local clients receive valid SSL certificates.</li>
</ul>
</li>
<li><p><strong>Avoid External Dependencies</strong>:</p><ul>
<li>By resolving domains locally, you eliminate the need for local traffic to pass through Cloudflare, improving performance and reliability.</li>
</ul>
</li>
<li><p><strong>Monitor Logs</strong>:</p><ul>
<li>Regularly check your web server logs and Pi-hole logs to ensure everything is functioning as expected.</li>
</ul>
</li>
</ol>
<hr>
<h2 id="conclusion"><strong>Conclusion</strong></h2>
<p>When using Cloudflare for external access, it’s crucial to configure your local network to handle all domains and subdomains internally. By forwarding all domains to your local server, disabling upstream DNS forwarding, and securing them with Let’s Encrypt certificates, you can ensure seamless and secure access for both local and external clients.</p><p>This approach eliminates intermittent SSL errors, improves performance, and provides a consistent user experience across your network. If you follow these steps, your setup will be robust and reliable for all users.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Fixing PushRejectedError in Publii CMS While Syncing with GitHub</title>
        <author>
            <name>Ehmad</name>
        </author>
        <link href="https://blog.ehmad.site/fixing-pushrejectederror-in-publii-cms-while-syncing-with-github/"/>
        <id>https://blog.ehmad.site/fixing-pushrejectederror-in-publii-cms-while-syncing-with-github/</id>

        <updated>2025-03-03T11:21:27+05:00</updated>
            <summary>
                <![CDATA[
                    Issue Overview When using Publii CMS to sync a site to GitHub, you may encounter this error: ERROR: PushRejectedError: Push rejected because it was not a simple fast-forward. Use &quot;force: true&quot; to override. This happens because Publii tries to push changes to the blog branch,&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h2 id="issue-overview"><strong>Issue Overview</strong></h2>
<p>When using <strong>Publii CMS</strong> to sync a site to GitHub, you may encounter this error:</p><pre><code>ERROR: PushRejectedError: Push rejected because it was not a simple fast-forward. Use &quot;force: true&quot; to override.
</code></pre>
<p>This happens because <strong>Publii tries to push changes to the <code>blog</code> branch</strong>, but GitHub has a newer version of that branch (with the Azure workflow file). Since Publii does not pull before pushing, Git rejects the push.</p><p>If you <strong>force push</strong>, you risk overwriting and deleting important files, such as your <strong>GitHub Actions workflow</strong> that automates deployments to Azure.</p><h2 id="solution-pull-changes-before-syncing"><strong>Solution: Pull Changes Before Syncing</strong></h2>
<p>To prevent the workflow from being deleted, you must <strong>manually pull the latest changes before syncing</strong> in Publii.</p><h3 id="step-by-step-fix-using-git"><strong>Step-by-Step Fix Using Git</strong></h3>
<ol>
<li><strong>Open your terminal or command prompt.</strong></li>
<li><strong>Navigate to your Publii website folder.</strong><pre><code class="language-sh">cd path/to/your/publii/site/output
</code></pre>
 <em>(Replace <code>path/to/your/publii/site/output</code> with the actual path)</em></li>
<li><strong>Pull the latest changes from GitHub.</strong><pre><code class="language-sh">git pull origin blog --rebase
</code></pre>
 If there are conflicts, Git will ask you to resolve them.</li>
<li><strong>Go back to Publii and sync again.</strong><ul>
<li>Since Publii now has the latest version (including the workflow), it won’t overwrite it.</li>
</ul>
</li>
</ol>
<h2 id="alternative-exclude-githubworkflows-from-publii-sync"><strong>Alternative: Exclude <code>.github/workflows</code> from Publii Sync</strong></h2>
<p>If Publii is overwriting everything in the <code>blog</code> branch, you can <strong>exclude the <code>.github</code> folder</strong> (which contains your workflow file) from being removed.</p><h3 id="steps-to-exclude-files-in-publii"><strong>Steps to Exclude Files in Publii:</strong></h3>
<ol>
<li>In <strong>Publii</strong>, go to:
<strong>Settings → Server → Additional Sync Options</strong></li>
<li>Look for an <strong>“Exclude files/folders from sync”</strong> option.</li>
<li>Add <code>.github/workflows/</code> to the exclusion list.
<em>(This prevents Publii from deleting the workflow every time you sync.)</em></li>
</ol>
<h2 id="unofficial-fix-store-workflow-files-inside-publiis-input-folder"><strong>Unofficial Fix: Store Workflow Files Inside Publii’s Input Folder</strong></h2>
<p>Since Publii syncs only what’s inside the <code>output/</code> folder, a workaround is to place the <code>.github/workflows</code> directory inside <strong><code>input/root-files/</code></strong>. This ensures that Publii will upload the workflow file along with the rest of the website content.</p><h3 id="steps-to-apply-this-fix"><strong>Steps to Apply This Fix:</strong></h3>
<ol>
<li><strong>Navigate to your Publii site’s input folder:</strong><pre><code class="language-sh">cd path/to/your/publii/site/input/root-files
</code></pre>
</li>
<li><strong>Create the <code>.github/workflows/</code> directory:</strong><pre><code class="language-sh">mkdir -p .github/workflows
</code></pre>
</li>
<li><strong>Move your workflow file into this directory:</strong><pre><code class="language-sh">mv path/to/your/workflow.yml .github/workflows/
</code></pre>
</li>
<li><strong>Sync your site again using Publii.</strong><ul>
<li>The workflow file should now be included automatically in the deployment.</li>
</ul>
</li>
</ol>
<p>You can read more about this fix in this GitHub issue:<br>🔗 <a href="https://github.com/GetPublii/Publii/issues/2077">Publii GitHub Issue #2077</a></p><h2 id="what-happens-now"><strong>What Happens Now?</strong></h2>
<ul>
<li><strong>You pull the latest changes first (keeps workflow).</strong></li>
<li><strong>Then you sync with Publii (adds articles).</strong></li>
<li><strong>No workflow deletion, no Git errors. �</strong>*</li>
<li><strong>If you store workflows in <code>input/root-files/</code>, Publii will automatically upload them every sync.</strong></li>
</ul>
<p>By following these steps, you can seamlessly update your blog content without interfering with your deployment workflow.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Resolving Git Merge Conflicts: A Step-by-Step Guide</title>
        <author>
            <name>Ehmad</name>
        </author>
        <link href="https://blog.ehmad.site/resolving-git-merge-conflicts-a-step-by-step-guide/"/>
        <id>https://blog.ehmad.site/resolving-git-merge-conflicts-a-step-by-step-guide/</id>

        <updated>2025-03-03T10:59:58+05:00</updated>
            <summary>
                <![CDATA[
                    Git is a powerful version control system that allows developers to collaborate on projects efficiently. However, when multiple contributors work on the same branch or repository, conflicts can arise during merges. These conflicts occur when Git cannot automatically reconcile differences between the local and remote&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>Git is a powerful version control system that allows developers to collaborate on projects efficiently. However, when multiple contributors work on the same branch or repository, conflicts can arise during merges. These conflicts occur when Git cannot automatically reconcile differences between the local and remote versions of files. In this article, we’ll explore a real-world example of Git merge conflicts and provide a step-by-step guide to resolving them.</p><hr>
<h2 id="understanding-the-conflict-scenario">Understanding the Conflict Scenario</h2>
<p>In our example, a developer attempted to pull updates from the <code>main</code> branch of a remote repository using the command:</p><pre><code class="language-bash">git pull origin main
</code></pre>
<p>However, the operation resulted in numerous merge conflicts. The conflict log revealed two primary types of conflicts:</p><ol>
<li><p><strong>Modify/Delete Conflicts</strong>:</p><ul>
<li>Some files were deleted in the local branch (<code>HEAD</code>) but modified in the remote branch (<code>origin/main</code>).</li>
<li>Git could not determine whether to keep the remote changes or respect the local deletion.</li>
</ul>
</li>
<li><p><strong>Rename/Delete Conflicts</strong>:</p><ul>
<li>A file was renamed in the remote branch but deleted in the local branch.</li>
<li>Git was unsure whether to apply the rename or honor the deletion.</li>
</ul>
</li>
</ol>
<p>The conflicting files included HTML pages, CSS stylesheets, configuration files, and metadata files like <code>feed.json</code> and <code>sitemap.xml</code>. These files are critical for maintaining the structure and functionality of the project, so resolving the conflicts correctly is essential.</p><hr>
<h2 id="why-do-merge-conflicts-happen">Why Do Merge Conflicts Happen?</h2>
<p>Merge conflicts typically occur due to one of the following reasons:</p><ol>
<li><p><strong>Divergent Changes</strong>:</p><ul>
<li>Multiple contributors modify the same part of a file or delete files independently.</li>
</ul>
</li>
<li><p><strong>Outdated Local Branch</strong>:</p><ul>
<li>The local branch has not been updated with the latest changes from the remote repository, leading to inconsistencies.</li>
</ul>
</li>
<li><p><strong>File Renaming or Deletion</strong>:</p><ul>
<li>Files are renamed or deleted in one branch while being modified in another.</li>
</ul>
</li>
</ol>
<p>In our case, the developer’s local branch had deleted several files, while the remote branch had made significant modifications to those same files. This divergence caused Git to flag conflicts during the merge process.</p><hr>
<h2 id="how-to-resolve-merge-conflicts">How to Resolve Merge Conflicts</h2>
<p>Resolving merge conflicts requires careful consideration of the changes in both branches. Below is a step-by-step guide to resolving the conflicts described in our scenario.</p><hr>
<h3 id="step-1-review-the-conflicts">Step 1: Review the Conflicts</h3>
<p>Run the following command to identify all conflicting files:</p><pre><code class="language-bash">git status
</code></pre>
<p>This will display a list of files marked as “both modified” or “deleted by us/them.” For example:</p><pre><code>Unmerged paths:
  both modified:   index.html
  deleted by us:   assets/css/style.css
</code></pre>
<hr>
<h3 id="step-2-decide-on-a-resolution-strategy">Step 2: Decide on a Resolution Strategy</h3>
<p>For each conflicting file, decide whether to:</p><ol>
<li><p><strong>Keep the Remote Version</strong>:</p><ul>
<li>If the remote changes are important and should be retained, use:<pre><code class="language-bash">git checkout --theirs &lt;file&gt;
</code></pre>
</li>
</ul>
</li>
<li><p><strong>Keep the Local Version</strong>:</p><ul>
<li>If the local deletion was intentional and the remote changes are irrelevant, use:<pre><code class="language-bash">git checkout --ours &lt;file&gt;
</code></pre>
</li>
</ul>
</li>
<li><p><strong>Manually Merge</strong>:</p><ul>
<li>If both versions contain valuable changes, manually edit the file to combine the changes. Open the file in your text editor, resolve any conflict markers (e.g., <code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</code>), and save the file.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="step-3-handle-renamedelete-conflicts">Step 3: Handle Rename/Delete Conflicts</h3>
<p>For files involved in rename/delete conflicts, decide whether to:</p><ol>
<li><p><strong>Apply the Rename</strong>:</p><ul>
<li>If the rename is valid and the file should exist, use:<pre><code class="language-bash">git mv &lt;old-name&gt; &lt;new-name&gt;
</code></pre>
</li>
</ul>
</li>
<li><p><strong>Delete the File</strong>:</p><ul>
<li>If the file should no longer exist, remove it:<pre><code class="language-bash">git rm &lt;file&gt;
</code></pre>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="step-4-mark-conflicts-as-resolved">Step 4: Mark Conflicts as Resolved</h3>
<p>After resolving each conflict, stage the resolved files:</p><pre><code class="language-bash">git add &lt;file&gt;
</code></pre>
<p>Repeat this process for all conflicting files.</p><hr>
<h3 id="step-5-complete-the-merge">Step 5: Complete the Merge</h3>
<p>Once all conflicts are resolved and staged, complete the merge by committing the changes:</p><pre><code class="language-bash">git commit
</code></pre>
<p>Git will generate a merge commit message. You can edit it if needed.</p><hr>
<h3 id="step-6-push-the-changes">Step 6: Push the Changes</h3>
<p>Finally, push the resolved changes to the remote repository:</p><pre><code class="language-bash">git push origin main
</code></pre>
<hr>
<h2 id="best-practices-to-avoid-merge-conflicts">Best Practices to Avoid Merge Conflicts</h2>
<p>While conflicts are inevitable in collaborative projects, you can minimize their occurrence by following these best practices:</p><ol>
<li><p><strong>Frequent Pulls</strong>:</p><ul>
<li>Regularly pull updates from the remote repository to keep your local branch up-to-date.</li>
</ul>
</li>
<li><p><strong>Clear Communication</strong>:</p><ul>
<li>Coordinate with your team to avoid working on the same files simultaneously.</li>
</ul>
</li>
<li><p><strong>Feature Branches</strong>:</p><ul>
<li>Use feature branches for new developments and merge them into the main branch after thorough testing.</li>
</ul>
</li>
<li><p><strong>Code Reviews</strong>:</p><ul>
<li>Conduct code reviews before merging branches to ensure compatibility.</li>
</ul>
</li>
<li><p><strong>Automated Testing</strong>:</p><ul>
<li>Implement automated tests to catch integration issues early.</li>
</ul>
</li>
</ol>
<hr>
<h2 id="conclusion">Conclusion</h2>
<p>Merge conflicts are a natural part of collaborative software development. While they can be frustrating, understanding the root cause and following a systematic resolution process can help you overcome them efficiently. By keeping your branches synchronized, communicating effectively with your team, and adopting best practices, you can reduce the likelihood of conflicts and maintain a smooth workflow.</p><p>Remember, resolving conflicts is not just about fixing errors—it’s an opportunity to ensure that your project reflects the collective effort of your team. With patience and attention to detail, you can turn conflicts into collaboration success stories.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Self-Hosting Bitwarden with Docker Compose on Alpine linux</title>
        <author>
            <name>Ehmad</name>
        </author>
        <link href="https://blog.ehmad.site/self-hosting-bitwarden-with-docker-compose-on-alpine-linux/"/>
        <id>https://blog.ehmad.site/self-hosting-bitwarden-with-docker-compose-on-alpine-linux/</id>

        <updated>2025-03-03T10:20:27+05:00</updated>
            <summary>
                <![CDATA[
                    Bitwarden is a popular open-source password manager that allows users to self-host their own instance for enhanced privacy and control. Using Docker Compose, you can deploy Bitwarden with a custom network and static IP addresses, making it ideal for homelab enthusiasts or small organizations. This&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>Bitwarden is a popular open-source password manager that allows users to self-host their own instance for enhanced privacy and control. Using Docker Compose, you can deploy Bitwarden with a custom network and static IP addresses, making it ideal for homelab enthusiasts or small organizations. This guide walks through setting up the Bitwarden unified beta deployment (<code>bitwarden/self-host:beta</code>) with a MariaDB database, connected to an existing Docker network, and troubleshoot common issues along the way.</p><h2 id="prerequisites">Prerequisites</h2>
<ul>
<li>Docker and Docker Compose installed on your system.</li>
<li>A custom Docker network (e.g., <code>homelab_private_network</code>) already created.</li>
<li>Basic familiarity with Docker commands and YAML configuration.</li>
</ul>
<h2 id="step-1-define-the-docker-compose-file">Step 1: Define the Docker Compose File</h2>
<p>The Bitwarden unified deployment simplifies self-hosting by bundling most components into a single container, though it still requires a separate database. We’ll use MariaDB for this setup. Below is a <code>docker-compose.yml</code> file configured to join an existing network with static IPs.</p><h3 id="docker-composeyml"><code>docker-compose.yml</code></h3>
<pre><code class="language-yaml">services:
  bitwarden:
    depends_on:
      - db
    env_file:
      - settings.env
    image: bitwarden/self-host:beta
    restart: always
    ports:
      - &quot;80:8080&quot;
      - &quot;443:8443&quot;
    volumes:
      - ./bitwarden-data:/etc/bitwarden
      - ./logs:/var/log/bitwarden
    networks:
      homelab_private_network:
        ipv4_address: 192.168.2.110

  db:
    environment:
      MARIADB_USER: &quot;bitwarden&quot;
      MARIADB_PASSWORD: &quot;[REDACTED]&quot;
      MARIADB_DATABASE: &quot;bitwarden_vault&quot;
      MARIADB_RANDOM_ROOT_PASSWORD: &quot;true&quot;
    image: mariadb:10
    restart: always
    volumes:
      - ./db-data:/var/lib/mysql
    networks:
      homelab_private_network:
        ipv4_address: 192.168.2.111

networks:
  homelab_private_network:
    external: true
</code></pre>
<h3 id="key-components">Key Components</h3>
<ul>
<li><strong>Bitwarden Service</strong>: Uses the <code>bitwarden/self-host:beta</code> image, maps ports <code>80</code> and <code>443</code> to internal ports <code>8080</code> and <code>8443</code>, and mounts volumes for configuration and logs.</li>
<li><strong>MariaDB Service</strong>: Runs a MySQL-compatible database with predefined credentials and a random root password for security.</li>
<li><strong>Network</strong>: Joins an existing <code>homelab_private_network</code> with static IPs (<code>192.168.2.110</code> for Bitwarden, <code>192.168.2.111</code> for MariaDB).</li>
</ul>
<blockquote>
<p><strong>Note</strong>: The <code>version</code> field (e.g., <code>3.7</code>) is omitted as it’s obsolete in Docker Compose v2. The schema is inferred from the features used.</p></blockquote>
<h2 id="step-2-configure-environment-variables">Step 2: Configure Environment Variables</h2>
<p>Bitwarden requires environment variables for database connectivity and domain settings. Create a <code>settings.env</code> file in the same directory as <code>docker-compose.yml</code>.</p><h3 id="settingsenv"><code>settings.env</code></h3>
<pre><code>DOMAIN=http://192.168.2.110
DATABASE_PROVIDER=mysql
DATABASE_SERVER=db
DATABASE_NAME=bitwarden_vault
DATABASE_USERNAME=bitwarden
DATABASE_PASSWORD=[REDACTED]
ADMIN_ENABLED=true
SMTP_HOST=smtp.example.com
SMTP_PORT=587
SMTP_SSL=false
SMTP_USERNAME=[REDACTED]
SMTP_PASSWORD=[REDACTED]
</code></pre>
<h3 id="explanation">Explanation</h3>
<ul>
<li><code>DOMAIN</code>: Set to the Bitwarden container’s static IP (adjust for your setup or use a domain with SSL).</li>
<li><code>DATABASE_*</code>: Matches the MariaDB service’s credentials and service name.</li>
<li><code>ADMIN_ENABLED</code>: Enables the admin interface (optional).</li>
<li><code>SMTP_*</code>: Configures email notifications (optional; replace with your SMTP provider’s details).</li>
</ul>
<blockquote>
<p><strong>Security Tip</strong>: Replace <code>[REDACTED]</code> placeholders with strong, unique passwords and credentials.</p></blockquote>
<h2 id="step-3-prepare-the-environment">Step 3: Prepare the Environment</h2>
<p>Create directories for persistent data:</p><pre><code class="language-bash">mkdir -p ./bitwarden-data ./logs ./db-data
</code></pre>
<p>Ensure your custom network exists and its subnet includes the chosen IPs. Check with:</p><pre><code class="language-bash">docker network inspect homelab_private_network
</code></pre>
<p>Example output might show a subnet of <code>192.168.2.0/24</code>, supporting IPs from <code>192.168.2.1</code> to <code>192.168.2.254</code>. Adjust the IPs in <code>docker-compose.yml</code> if they don’t match (e.g., if the subnet were <code>192.168.0.0/24</code>, use <code>192.168.0.110</code> and <code>192.168.0.111</code>).</p><h2 id="step-4-deploy-the-services">Step 4: Deploy the Services</h2>
<p>Start the containers in detached mode:</p><pre><code class="language-bash">docker compose up -d
</code></pre>
<p>Verify they’re running:</p><pre><code class="language-bash">docker compose ps
</code></pre>
<p>You should see both <code>bitwarden</code> and <code>db</code> listed as <code>Up</code>.</p><h2 id="step-5-troubleshooting-common-issues">Step 5: Troubleshooting Common Issues</h2>
<h3 id="issue-1-obsolete-version-warning">Issue 1: Obsolete <code>version</code> Warning</h3>
<p>If you see a warning like:</p><pre><code>WARN[0000] docker-compose.yaml: the attribute `version` is obsolete...
</code></pre>
<p>Remove the <code>version</code> line from <code>docker-compose.yml</code>. It’s no longer needed in modern Docker Compose versions.</p><h3 id="issue-2-subnet-mismatch-error">Issue 2: Subnet Mismatch Error</h3>
<p>An error like:</p><pre><code>Error response from daemon: invalid config for network homelab_private_network: ... no configured subnet or ip-range contain the IP address 192.168.0.111
</code></pre>
<p>means the assigned IPs don’t match the network’s subnet. Inspect the network:</p><pre><code class="language-bash">docker network inspect homelab_private_network
</code></pre>
<p>If the subnet is <code>192.168.2.0/24</code> but your IPs are <code>192.168.0.x</code>, update <code>docker-compose.yml</code> to use <code>192.168.2.110</code> and <code>192.168.2.111</code>, then restart:</p><pre><code class="language-bash">docker compose down
docker compose up -d
</code></pre>
<h3 id="issue-3-container-exits-immediately">Issue 3: Container Exits Immediately</h3>
<p>If <code>bitwarden</code> or <code>db</code> stops (check with <code>docker compose ps -a</code>), view logs:</p><pre><code class="language-bash">docker compose logs bitwarden
docker compose logs db
</code></pre>
<p>Common causes include mismatched database credentials or missing SMTP settings (though SMTP is optional).</p><h2 id="step-6-access-bitwarden">Step 6: Access Bitwarden</h2>
<p>Once running, access Bitwarden at <code>http://192.168.2.110</code> (or your chosen IP) in a browser. Set up an account and test functionality. For production, consider:</p><ul>
<li>Adding SSL with a reverse proxy (e.g., Nginx or Traefik) <strong>Important</strong>.</li>
<li>Backing up the <code>./bitwarden-data</code> and <code>./db-data</code> directories.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Self-hosting Bitwarden with Docker Compose on a custom network offers flexibility and control over your password management on alpine linux. By assigning static IPs and troubleshooting subnet issues, you can integrate it seamlessly into an existing homelab setup. The unified beta deployment simplifies the process, making it accessible even for those new to Docker and alpine.</p><p>For advanced configurations, explore Bitwarden’s official <a href="https://bitwarden.com/help/install-on-premise-linux/">documentation</a> or integrate cloud features with an installation ID and key. Happy self-hosting!</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Tenda AC9 Firmware Analysis</title>
        <author>
            <name>Ehmad</name>
        </author>
        <link href="https://blog.ehmad.site/tenda-ac9-firmware-analysis/"/>
        <id>https://blog.ehmad.site/tenda-ac9-firmware-analysis/</id>

        <updated>2025-02-23T15:59:55+05:00</updated>
            <summary>
                <![CDATA[
                    Reverse Engineering the Tenda AC9 Firmware Routers are the unsung heroes of our connected lives—quietly humming away, keeping us online. But what’s really going on inside them? I recently got curious about my Tenda AC9 router and decided to crack open its firmware—US_AC9V1.0BR_V15.03.05.15_multi_TDE01.bin—to see what&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h1 id="reverse-engineering-the-tenda-ac9-firmware">Reverse Engineering the Tenda AC9 Firmware</h1>
<p>Routers are the unsung heroes of our connected lives—quietly humming away, keeping us online. But what’s <em>really</em> going on inside them? I recently got curious about my Tenda AC9 router and decided to crack open its firmware—<code>US_AC9V1.0BR_V15.03.05.15_multi_TDE01.bin</code>—to see what secrets it holds. Spoiler: it’s a mix of the expected, the quirky, and the slightly unsettling. Here’s what I found, how I got there, and why it might matter.</p><h2 id="step-1-cracking-the-shell-with-binwalk">Step 1: Cracking the Shell with Binwalk</h2>
<p>First things first—I needed to unpack the firmware. It’s a 7.4MB file, a u-boot uImage for a Linux/ARM kernel, timestamped October 29, 2020. Sounded like a job for <code>binwalk</code>, a go-to tool for firmware analysis. After installing it (<code>sudo apt install binwalk</code>), I ran a quick scan:</p><pre><code class="language-bash">wget https://github.com/mrxehmad/Tenda-AC9-Firmware-Analysis/raw/refs/heads/main/US_AC9V1.0BR_V15.03.05.15_multi_TDE01.zip
</code></pre>
<pre><code class="language-bash">binwalk US_AC9V1.0BR_V15.03.05.15_multi_TDE01.bin
</code></pre>
<p>The output revealed a TRX header, an LZMA-compressed kernel, and a SquashFS filesystem. To get inside, I extracted it:</p><pre><code class="language-bash">binwalk -e US_AC9V1.0BR_V15.03.05.15_multi_TDE01.bin
</code></pre>
<p>This gave me a folder with a compressed kernel (<code>5C.LZMA</code>) and a filesystem (<code>18EB48.squashfs</code>). One more command to decompress the filesystem:</p><pre><code class="language-bash">unsquashfs -f -d squashfs-root 18EB48.squashfs
</code></pre>
<p>And voilà—a treasure trove of files in <code>squashfs-root/</code>. Time to explore.</p><h2 id="step-2-open-ports-and-a-network-surprise">Step 2: Open Ports and a Network Surprise</h2>
<p>Before diving into the files, I scanned my router (<code>10.1.15.1</code>) with Nmap to see what it’s exposing:</p><pre><code>PORT      STATE SERVICE
80/tcp    open  http
5500/tcp  open  hotline
8180/tcp  open  unknown
9000/tcp  open  cslistener
10004/tcp open  emcrmirccd
</code></pre>
<p>Port 80? Expected for the web interface. 8180? Probably a secondary UI (more on that later). But 5500, 9000, and 10004? Those raised eyebrows. “Hotline” and “emcrmirccd” didn’t scream “router,” so I knew I had some digging to do.</p><h2 id="step-3-the-filesystem-tells-a-story">Step 3: The Filesystem Tells a Story</h2>
<p>Inside <code>squashfs-root/</code>, I found a mix of binaries, libraries, and configs. Nginx was running on port 8180 (<code>/usr/bin/nginx</code>), serving a Luci interface with a FastCGI backend on 8188 (<code>/usr/bin/app_data_center</code>). Port 80 was handled by <code>httpd</code>—standard stuff. But then things got interesting.</p><h3 id="hardcoded-connections">Hardcoded Connections</h3>
<p>Grepping through the files, I spotted hardcoded IPs and domains:</p><ul>
<li><code>cloud.tenda.com.cn</code></li>
<li><code>182.254.148.51</code></li>
<li><code>download.cloud.tenda.com.cn</code></li>
<li><code>182.254.218.214</code></li>
<li><code>182.254.136.200</code></li>
</ul>
<p>These popped up in files like <code>./bin/auto_discover</code>, which sends your MAC address and timestamp to <code>api.cloud.tenda.com.cn/route/mac/v1</code>. Device tracking, perhaps? Meanwhile, <code>httpd</code> fetches ad URLs from <code>api.cloud.tenda.com.cn/route/adverts/v1</code>, defaulting to <code>www.tenda.com.cn</code> if it fails. An old-school User-Agent (<code>MSIE 5.01</code>) hinted this code hasn’t been touched in years.</p><h3 id="quirky-binaries">Quirky Binaries</h3>
<ul>
<li><code>./bin/speedtest</code>: Pings domains like <code>www.taobao.com</code> and <code>www.google.com</code>—likely a bandwidth test.</li>
<li><code>./bin/88ip</code>: Sends XML to <code>link.dipserver.com</code> for dynamic DNS.</li>
<li><code>./bin/logserver</code>: Tries (and often fails) to ship logs somewhere external.</li>
<li><code>./usr/sbin/telnetd</code>: A Telnet server! No startup script activated it, but its presence felt like a debug leftover.</li>
</ul>
<h3 id="firewall-rules">Firewall Rules</h3>
<p>Hardcoded <code>iptables</code> commands caught my eye:</p><pre><code>iptables -A OUTPUT -p udp --dport %d -m state --state NEW -j %s
iptables -A %s -o %s -j DROP
</code></pre>
<p>These seem to manage outbound traffic—maybe to those Tenda cloud servers?</p><h2 id="step-4-what-does-it-mean">Step 4: What Does It Mean?</h2>
<p>This firmware is chatty. It phones home to Tenda’s cloud, potentially sharing device info, fetching ads, and running services on non-standard ports (5500 and 10004 still elude me—debug backdoors?). The Telnet binary is dormant but tempting for anyone with root access. And those hardcoded IPs? A security researcher’s red flag—perfect for spoofing or tracking.</p><h2 id="why-it-matters">Why It Matters</h2>
<p>Routers like the Tenda AC9 are everywhere, yet we rarely peek inside. This little adventure showed me how much they’re doing behind the scenes—some useful, some questionable. I’ve dumped my findings on GitHub (link below) with extraction steps, hoping others might join the fun. Could 5500 be a mislabeled Telnet port? Is <code>libupnp.so</code> behind 9000? I’m a newbie at this, but tools like Ghidra are calling—I’ll dive deeper if you do.</p><p>What do you think? Ever analyzed your own gear? Let’s swap notes!</p><ul>
<li><a href="https://github.com/mrxehmad/Tenda-AC9-Firmware-Analysis">Tenda AC9 Firmware Analysis</a></li>
<li><a href="https://github.com/mrxehmad/api.cloud.tenda.com.cn">api.cloud.tenda.com.cn</a></li>
<li><a href="https://github.com/SC0p30N3/Tenda-AC15-Firmware-V15.03.05.18">Tenda AC15 Analysis</a> </li>
<li><a href="https://ea.github.io/blog/2013/10/18/tenda-backdoor/">Tenda Backdoor Blog</a></li>
</ul>

            ]]>
        </content>
    </entry>
    <entry>
        <title>User Reports Privacy Indicator Issue with Google Assistant on Pixel Phones</title>
        <author>
            <name>Ehmad</name>
        </author>
        <link href="https://blog.ehmad.site/user-reports-privacy-indicator-issue-with-google-assistant-on-pixel-phones/"/>
        <id>https://blog.ehmad.site/user-reports-privacy-indicator-issue-with-google-assistant-on-pixel-phones/</id>

        <updated>2025-02-14T18:35:30+05:00</updated>
            <summary>
                <![CDATA[
                    A Pixel phone user recently reported a potentially concerning behavior related to Google Assistant and the microphone privacy indicator. According to the user, when activating Google Assistant using the voice command “Hey Google,” the microphone privacy indicator did not appear immediately. However, once the conversation&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>A Pixel phone user recently reported a potentially concerning behavior related to Google Assistant and the microphone privacy indicator. According to the user, when activating Google Assistant using the voice command “Hey Google,” the microphone privacy indicator did not appear immediately. However, once the conversation with Google Assistant began, the indicator appeared, signaling that the microphone was in use. This raised questions about whether Google Assistant was listening before displaying the indicator.</p><h3 id="possible-explanations-for-this-behavior">Possible Explanations for This Behavior</h3>
<ol>
<li><p><strong>Wake-Up Happens at a Lower System Level</strong><br>Google Assistant continuously listens for the wake phrase “Hey Google” using on-device speech recognition. This process does not trigger the microphone indicator because it operates at a system level without actively recording or sending data. The indicator only appears once Google Assistant starts processing the user’s request.</p></li>
<li><p><strong>Delayed Privacy Indicator</strong><br>There might be a slight delay in the system UI updating to show the microphone indicator, especially if the phone is under load. This could explain why the indicator appears after Google Assistant starts responding rather than immediately upon activation.</p></li>
<li><p><strong>Different Microphone Access Levels</strong><br>System-level apps like Google Assistant might bypass standard privacy indicator rules when passively listening for the wake word. The microphone is formally marked “in use” only when the Assistant starts processing a request.</p></li>
<li><p><strong>Possible Software Bug</strong><br>If this behavior is new or inconsistent, it could be a software glitch introduced in a recent Android update. Google has previously adjusted privacy indicators, and any unexpected changes should be monitored for potential fixes in future updates.</p></li>
</ol>
<h3 id="how-users-can-investigate-further">How Users Can Investigate Further</h3>
<p>If you’re experiencing this issue and want to ensure your privacy, here are a few steps to take:</p><ul>
<li><p><strong>Check Mic Usage in Privacy Dashboard</strong><br>Navigate to <strong>Settings &gt; Privacy &gt; Permission Manager &gt; Microphone</strong> to see which apps have accessed the microphone and when.</p></li>
<li><p><strong>Disable “Hey Google” for Testing</strong><br>Try turning off the voice activation feature (<strong>Settings &gt; Google &gt; Assistant &gt; Hey Google &amp; Voice Match</strong>) and manually activating the Assistant with the power button or gesture. If the indicator appears immediately with manual activation, it suggests a difference in how Google Assistant handles wake-word detection.</p></li>
<li><p><strong>Use a Third-Party Mic Monitoring App</strong><br>Apps like <strong>Access Dots</strong> or <strong>Bouncer</strong> can provide additional insights into microphone access and alert users to unexpected mic activity.</p></li>
</ul>
<h3 id="should-users-be-concerned">Should Users Be Concerned?</h3>
<p>While this behavior does not necessarily indicate unauthorized microphone access, it does highlight a gap in transparency regarding when the microphone is actively listening. Google states that Assistant only listens for the wake word and does not store audio until activated. However, privacy-conscious users may want to take extra precautions to verify this claim.</p><p>If you’ve noticed similar behavior on your Pixel or another Android device, sharing your experience can help determine whether this is an isolated issue or a broader software concern.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>How to Use Discord Webhooks </title>
        <author>
            <name>Ehmad</name>
        </author>
        <link href="https://blog.ehmad.site/how-to-use-discord-webhooks/"/>
        <id>https://blog.ehmad.site/how-to-use-discord-webhooks/</id>

        <updated>2025-02-03T13:32:35+05:00</updated>
            <summary>
                <![CDATA[
                    Discord webhooks are a powerful tool for integrating external services with your Discord server. They allow you to automate messages, send notifications, and even create custom bots without needing to write complex code. In this article, we’ll explore what Discord webhooks are, how to set&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>Discord webhooks are a powerful tool for integrating external services with your Discord server. They allow you to automate messages, send notifications, and even create custom bots without needing to write complex code. In this article, we’ll explore what Discord webhooks are, how to set them up, and various ways you can use them to enhance your server.</p><hr>
<h2 id="what-are-discord-webhooks"><strong>What Are Discord Webhooks?</strong></h2>
<p>A webhook is essentially a way for an external application or service to send automated messages to a specific channel in your Discord server. Instead of manually posting updates, webhooks enable real-time communication between your server and other platforms like GitHub, Jenkins, monitoring tools, or even custom scripts.</p><p>Webhooks are lightweight, easy to set up, and don’t require you to build a full-fledged bot. They’re perfect for sending notifications, logging events, or automating repetitive tasks.</p><hr>
<h2 id="how-to-create-a-discord-webhook"><strong>How to Create a Discord Webhook</strong></h2>
<p>Before you can start using webhooks, you need to create one in your Discord server. Here’s how:</p><h3 id="step-1-navigate-to-channel-settings"><strong>Step 1: Navigate to Channel Settings</strong></h3>
<ol>
<li>Open your Discord server.</li>
<li>Go to the channel where you want the webhook to post messages.</li>
<li>Click on the gear icon (⚙️) next to the channel name to open the channel settings.</li>
</ol>
<h3 id="step-2-create-a-webhook"><strong>Step 2: Create a Webhook</strong></h3>
<ol>
<li>In the channel settings, go to <strong>Integrations</strong> &gt; <strong>Webhooks</strong>.</li>
<li>Click <strong>Create Webhook</strong>.</li>
<li>Give your webhook a name (e.g., “Notification Bot”).</li>
<li>Select the channel where the webhook will post messages.</li>
<li>Optionally, upload an avatar image to customize the webhook’s appearance.</li>
<li>Click <strong>Copy Webhook URL</strong> and save it securely. This URL is essential for sending messages via the webhook.</li>
</ol>
<hr>
<h2 id="how-to-send-messages-using-a-webhook"><strong>How to Send Messages Using a Webhook</strong></h2>
<p>Once you’ve created a webhook, you can start sending messages to your Discord server. Below are examples of how to do this using different methods.</p><h3 id="1-using-curl-command"><strong>1. Using <code>curl</code> Command</strong></h3>
<p>You can send a simple message to your Discord channel using the <code>curl</code> command in your terminal:</p><pre><code class="language-bash">curl -X POST -H &quot;Content-Type: application/json&quot; \
-d &#39;{&quot;content&quot;: &quot;Hello, this is a test message from my webhook!&quot;}&#39; \
https://discord.com/api/webhooks/YOUR_WEBHOOK_URL_HERE
</code></pre>
<p>Replace <code>YOUR_WEBHOOK_URL_HERE</code> with the actual webhook URL you copied earlier.</p><h3 id="2-using-python"><strong>2. Using Python</strong></h3>
<p>If you prefer scripting, here’s how to send a message using Python:</p><pre><code class="language-python">import requests

webhook_url = &quot;https://discord.com/api/webhooks/YOUR_WEBHOOK_URL_HERE&quot;
data = {&quot;content&quot;: &quot;Hello, this is a test message from my webhook!&quot;}

response = requests.post(webhook_url, json=data)

if response.status_code == 204:
    print(&quot;Message sent successfully!&quot;)
else:
    print(f&quot;Failed to send message: {response.status_code}, {response.text}&quot;)
</code></pre>
<h3 id="3-using-postman-or-insomnia"><strong>3. Using Postman or Insomnia</strong></h3>
<p>For non-programmers, tools like <a href="https://www.postman.com/">Postman</a> or <a href="https://insomnia.rest/">Insomnia</a> can be used to manually send HTTP POST requests to the webhook URL.</p><hr>
<h2 id="customizing-webhook-messages"><strong>Customizing Webhook Messages</strong></h2>
<p>Discord webhooks allow you to customize the sender’s name, avatar, and even send rich embeds for more visually appealing messages.</p><h3 id="1-custom-sender-name-and-avatar"><strong>1. Custom Sender Name and Avatar</strong></h3>
<p>You can override the default webhook name and avatar by including the <code>username</code> and <code>avatar_url</code> fields in your payload:</p><pre><code class="language-json">{
  &quot;username&quot;: &quot;My Custom Bot&quot;,
  &quot;avatar_url&quot;: &quot;https://example.com/avatar.png&quot;,
  &quot;content&quot;: &quot;This message is sent by a custom bot!&quot;
}
</code></pre>
<h3 id="2-sending-rich-embeds"><strong>2. Sending Rich Embeds</strong></h3>
<p>Embeds allow you to send structured and visually appealing messages. Here’s an example of an embed payload:</p><pre><code class="language-json">{
  &quot;embeds&quot;: [
    {
      &quot;title&quot;: &quot;New Blog Post!&quot;,
      &quot;description&quot;: &quot;Check out our latest article on how to use webhooks.&quot;,
      &quot;url&quot;: &quot;https://example.com/blog-post&quot;,
      &quot;color&quot;: 16711680,
      &quot;fields&quot;: [
        {
          &quot;name&quot;: &quot;Author&quot;,
          &quot;value&quot;: &quot;John Doe&quot;,
          &quot;inline&quot;: true
        },
        {
          &quot;name&quot;: &quot;Published Date&quot;,
          &quot;value&quot;: &quot;2023-10-01&quot;,
          &quot;inline&quot;: true
        }
      ],
      &quot;thumbnail&quot;: {
        &quot;url&quot;: &quot;https://example.com/thumbnail.jpg&quot;
      }
    }
  ]
}
</code></pre>
<p>Send this payload using <code>curl</code>, Python, or any other method.</p><hr>
<h2 id="use-cases-for-discord-webhooks"><strong>Use Cases for Discord Webhooks</strong></h2>
<p>Here are some practical ways you can use webhooks to enhance your Discord server:</p><h3 id="1-notifications-from-external-services"><strong>1. Notifications from External Services</strong></h3>
<ul>
<li><strong>GitHub</strong>: Get notifications for new commits, issues, or pull requests.</li>
<li><strong>Jenkins</strong>: Notify your team when a build succeeds or fails.</li>
<li><strong>Uptime Monitoring</strong>: Alert your team if a server goes down.</li>
</ul>
<h3 id="2-logging-system"><strong>2. Logging System</strong></h3>
<p>Use webhooks to log events from your applications or servers. For example:</p><ul>
<li>Log errors or warnings directly to a dedicated “logs” channel.</li>
<li>Monitor server health and send alerts when something goes wrong.</li>
</ul>
<h3 id="3-moderation-alerts"><strong>3. Moderation Alerts</strong></h3>
<p>Set up a script or bot that monitors your server for certain activities (e.g., spam detection, keyword filtering) and sends moderation alerts via the webhook.</p><h3 id="4-game-or-event-notifications"><strong>4. Game or Event Notifications</strong></h3>
<p>If you’re running a gaming community, use webhooks to notify users about:</p><ul>
<li>Upcoming game releases.</li>
<li>Server maintenance schedules.</li>
<li>Tournament announcements.</li>
</ul>
<h3 id="5-automated-announcements"><strong>5. Automated Announcements</strong></h3>
<p>Use webhooks to automate recurring announcements, such as:</p><ul>
<li>Daily reminders.</li>
<li>Weekly updates.</li>
<li>Event countdowns.</li>
</ul>
<hr>
<h2 id="security-tips-for-using-webhooks"><strong>Security Tips for Using Webhooks</strong></h2>
<p>While webhooks are convenient, they can also pose security risks if not handled properly. Here are some tips to keep your webhooks secure:</p><ol>
<li><strong>Keep Your Webhook URL Secret</strong>: Treat your webhook URL like a password. Anyone with access to it can send messages to your server.</li>
<li><strong>Delete Unused Webhooks</strong>: If you no longer need a webhook, delete it to prevent misuse.</li>
<li><strong>Regenerate Webhooks if Compromised</strong>: If you suspect your webhook has been compromised, delete it and create a new one.</li>
<li><strong>Limit Permissions</strong>: Ensure the webhook only posts to the intended channel and doesn’t have unnecessary permissions.</li>
</ol>
<hr>
<h2 id="troubleshooting-common-issues"><strong>Troubleshooting Common Issues</strong></h2>
<h3 id="1-unknown-webhook-error"><strong>1. “Unknown Webhook” Error</strong></h3>
<p>This error occurs if the webhook URL is invalid, deleted, or disabled. Double-check the URL and ensure the webhook still exists in your server settings.</p><h3 id="2-rate-limits"><strong>2. Rate Limits</strong></h3>
<p>Discord imposes rate limits on webhooks. If you’re sending too many requests in a short period, you may be temporarily blocked. Wait a few minutes before trying again.</p><h3 id="3-formatting-issues"><strong>3. Formatting Issues</strong></h3>
<p>Ensure your JSON payload is correctly formatted. Missing brackets, quotes, or commas can cause errors.</p><hr>
<h2 id="conclusion"><strong>Conclusion</strong></h2>
<p>Discord webhooks are a versatile and easy-to-use tool for automating messages and integrating external services with your server. Whether you’re sending notifications, logging events, or creating custom bots, webhooks can help streamline your workflows and keep your community informed.</p><p>By following the steps outlined in this guide, you can set up and use webhooks effectively while keeping your server secure. Experiment with different use cases and customize your messages to make the most of this powerful feature!</p><p>Happy automating! 🚀</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Phishing Attack Chain Report - Fiverr</title>
        <author>
            <name>Ehmad</name>
        </author>
        <link href="https://blog.ehmad.site/phishing-attack-chain-report-fiverr/"/>
        <id>https://blog.ehmad.site/phishing-attack-chain-report-fiverr/</id>

        <updated>2025-01-26T21:23:13+05:00</updated>
            <summary>
                <![CDATA[
                    Phishing Attack Chain Report Incident Overview: I recently encountered a phishing attempt within my Fiverr inbox. The attacker used a GIF image to bypass Fiverr’s security measures and avoid detection. The GIF contained a QR code that, when scanned, directed me to a phishing page.
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p><strong>Phishing Attack Chain Report</strong></p><p><strong>Incident Overview:</strong>
I recently encountered a phishing attempt within my Fiverr inbox. The attacker used a GIF image to bypass Fiverr’s security measures and avoid detection. The GIF contained a QR code that, when scanned, directed me to a phishing page.</p><p><strong>Phishing URL:</strong><br>Initial URL: <a href="https://fiverr.offer984732.cfd/7ky7njr1pzz7970t">https://fiverr.offer984732.cfd/7ky7njr1pzz7970t</a></p><p><strong>Attack Chain:</strong></p><ol>
<li><p><strong>Initial Contact:</strong>  </p><ul>
<li>The phishing attempt began with a message in my Fiverr inbox containing a GIF image.</li>
<li>The GIF displayed a QR code instead of a direct link, likely to circumvent Fiverr’s security mechanisms.</li>
</ul>
</li>
<li><p><strong>Phishing Page:</strong>  </p><ul>
<li>Scanning the QR code redirected me to a phishing website disguised to resemble Fiverr’s official payment page.</li>
<li>The page prompted me to “receive payment” from a client by adding my credit card details.</li>
<li>Notably, right-clicking and other browser functions, such as saving the page, were disabled to prevent analysis or inspection.</li>
</ul>
</li>
<li><p><strong>Redirection to Payment Form:</strong>  </p><ul>
<li>Upon attempting to “receive funds,” I was redirected to another URL:
<a href="https://fiverr.offer984732.cfd/merchant/order/7ky7njr1pzz7970t">https://fiverr.offer984732.cfd/merchant/order/7ky7njr1pzz7970t</a></li>
<li>This page requested full credit card details under the guise of processing the payment.</li>
</ul>
</li>
<li><p><strong>Transaction Failure:</strong>  </p><ul>
<li>After entering test card details, the page displayed a “transaction failed” message.</li>
<li>This indicates the phishing attempt’s goal was purely to collect financial information rather than process any real transaction.</li>
</ul>
</li>
</ol>
<p><strong>Observations and Indicators of Compromise (IoCs):</strong></p><ul>
<li>The URL contains suspicious subdomains and random alphanumeric paths.</li>
<li>The use of QR codes in phishing attempts to avoid link detection.</li>
<li>Browser functions such as right-clicking being disabled, which is a common phishing tactic.</li>
<li>Fake payment processing followed by a transaction failure message.</li>
</ul>
<p><strong>Recommendations:</strong></p><ol>
<li><strong>Avoid Scanning Unknown QR Codes:</strong>  <ul>
<li>Do not scan QR codes from unknown or unverified sources, especially in online freelance platforms.</li>
</ul>
</li>
<li><strong>Verify URLs Carefully:</strong>  <ul>
<li>Always cross-check URLs and avoid interacting with unfamiliar domains.</li>
</ul>
</li>
<li><strong>Enable Security Features:</strong>  <ul>
<li>Use browser extensions and security tools to identify phishing sites.</li>
</ul>
</li>
<li><strong>Report the Incident:</strong>  <ul>
<li>Report such incidents to Fiverr’s support team and relevant cybersecurity authorities.</li>
</ul>
</li>
<li><strong>Monitor Financial Accounts:</strong>  <ul>
<li>If any sensitive information was entered, monitor bank statements and enable fraud alerts.</li>
</ul>
</li>
</ol>
<p><strong>Conclusion:</strong>
This phishing attempt leveraged an innovative technique by embedding a QR code in a GIF to bypass detection and used social engineering to prompt credit card submission. Users should remain vigilant and report suspicious activity to prevent potential financial loss.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Data Communications and Networking 5th edition</title>
        <author>
            <name>Ehmad</name>
        </author>
        <link href="https://blog.ehmad.site/data-communications-and-networking-5th-edition/"/>
        <id>https://blog.ehmad.site/data-communications-and-networking-5th-edition/</id>
            <category term="book summery"/>

        <updated>2025-01-08T19:14:02+05:00</updated>
            <summary>
                <![CDATA[
                    Chapter 18: Introduction to Network Layer in Data Communications and Networking (5th edition) by Behrouz A. Forouzan: The network layer plays a critical role in delivering data between devices over interconnected networks. It provides the following key services: Packet switching is a fundamental method for&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p><strong>Chapter 18: Introduction to Network Layer</strong> in Data Communications and Networking (5th edition) by Behrouz A. Forouzan:</p><hr>
<h3 id="181-network-layer-services"><strong>18.1 NETWORK-LAYER SERVICES</strong></h3>
<p>The network layer plays a critical role in delivering data between devices over interconnected networks. It provides the following key services:</p><h4 id="1811-packetizing"><strong>18.1.1 Packetizing</strong></h4>
<ul>
<li><strong>Definition</strong>: Packetizing is the process of dividing large chunks of data into smaller units called packets, which are easier to manage, transmit, and process.</li>
<li><strong>Structure</strong>: Each packet contains:<ul>
<li><strong>Payload</strong>: The actual data being transmitted.</li>
<li><strong>Header</strong>: Contains metadata such as the source and destination addresses, sequence numbers, and error-checking information.</li>
</ul>
</li>
<li><strong>Purpose</strong>: <ul>
<li>Facilitates efficient use of the network.</li>
<li>Allows for error detection and recovery by retransmitting only the affected packets instead of the entire data.</li>
</ul>
</li>
</ul>
<h4 id="1812-routing-and-forwarding"><strong>18.1.2 Routing and Forwarding</strong></h4>
<ul>
<li><strong>Routing</strong>:<ul>
<li>Involves determining the optimal path for packets to travel from the source to the destination.</li>
<li>Algorithms like Dijkstra’s and Bellman-Ford are commonly used.</li>
<li>Factors considered: network topology, link costs, and policy constraints.</li>
</ul>
</li>
<li><strong>Forwarding</strong>:<ul>
<li>The act of moving a packet to its next destination (next-hop router or the final recipient).</li>
<li>Based on information in the routing table, the router decides the best outgoing link.</li>
</ul>
</li>
</ul>
<h4 id="1813-other-services"><strong>18.1.3 Other Services</strong></h4>
<ol>
<li><strong>Error Handling</strong>:<ul>
<li>Detects and sometimes corrects errors in transmitted packets.</li>
<li>Error detection methods like checksums are used.</li>
</ul>
</li>
<li><strong>Quality of Service (QoS)</strong>:<ul>
<li>Ensures performance requirements such as bandwidth, delay, and jitter are met.</li>
<li>Differentiates traffic types (e.g., voice, video, or text) to prioritize critical data.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="182-packet-switching"><strong>18.2 PACKET SWITCHING</strong></h3>
<p>Packet switching is a fundamental method for data transfer in modern networks, enabling flexibility and efficiency. It involves breaking data into smaller packets that are sent independently.</p><h4 id="1821-datagram-approach-connectionless-service"><strong>18.2.1 Datagram Approach: Connectionless Service</strong></h4>
<ul>
<li><strong>Characteristics</strong>:<ul>
<li>Each packet is treated as an independent entity.</li>
<li>Packets may take different paths through the network to reach the destination.</li>
<li>Each packet includes full routing information (source and destination addresses).</li>
</ul>
</li>
<li><strong>Advantages</strong>:<ul>
<li>Highly scalable and robust.</li>
<li>No need for establishing or maintaining a connection.</li>
</ul>
</li>
<li><strong>Example</strong>: The Internet Protocol (IP) operates using this approach.</li>
</ul>
<h4 id="1822-virtual-circuit-approach-connection-oriented-service"><strong>18.2.2 Virtual-Circuit Approach: Connection-Oriented Service</strong></h4>
<ul>
<li><strong>Characteristics</strong>:<ul>
<li>A logical connection is established between the source and destination before data transfer.</li>
<li>All packets follow the same pre-established path, ensuring order.</li>
</ul>
</li>
<li><strong>Advantages</strong>:<ul>
<li>Reliable communication with guaranteed sequencing and error detection.</li>
<li>Simplified processing at intermediate routers.</li>
</ul>
</li>
<li><strong>Example</strong>: Asynchronous Transfer Mode (ATM) and Multi-Protocol Label Switching (MPLS).</li>
</ul>
<hr>
<h3 id="183-network-layer-performance"><strong>18.3 NETWORK-LAYER PERFORMANCE</strong></h3>
<p>The efficiency and reliability of the network layer are measured using the following metrics:</p><h4 id="1831-delay"><strong>18.3.1 Delay</strong></h4>
<ul>
<li><strong>Types of Delay</strong>:<ol>
<li><strong>Propagation Delay</strong>: <ul>
<li>Time for a signal to travel from source to destination through the physical medium.</li>
<li>Formula: ( \text{Propagation Delay} = \frac{\text{Distance}}{\text{Propagation Speed}} )</li>
</ul>
</li>
<li><strong>Transmission Delay</strong>: <ul>
<li>Time required to push all bits of a packet onto the transmission medium.</li>
<li>Formula: ( \text{Transmission Delay} = \frac{\text{Packet Size}}{\text{Bandwidth}} )</li>
</ul>
</li>
<li><strong>Queuing Delay</strong>:<ul>
<li>Time a packet spends waiting in a router’s queue before being processed or transmitted.</li>
<li>Varies depending on network congestion.</li>
</ul>
</li>
<li><strong>Processing Delay</strong>:<ul>
<li>Time taken by a router to examine and forward a packet.</li>
<li>Includes route lookup, header parsing, and error checking.</li>
</ul>
</li>
</ol>
</li>
</ul>
<h4 id="1832-throughput"><strong>18.3.2 Throughput</strong></h4>
<ul>
<li><strong>Definition</strong>: The rate at which data is successfully transmitted and received over the network.</li>
<li><strong>Factors Affecting Throughput</strong>:<ul>
<li><strong>Bandwidth</strong>: The maximum data transfer rate of the medium.</li>
<li><strong>Network Congestion</strong>: Overloaded links or routers reduce throughput.</li>
<li><strong>Protocol Overhead</strong>: Header and control data can consume significant portions of bandwidth.</li>
</ul>
</li>
</ul>
<h4 id="1833-packet-loss"><strong>18.3.3 Packet Loss</strong></h4>
<ul>
<li><strong>Definition</strong>: The percentage of packets that fail to reach their destination due to errors, congestion, or buffer overflow at routers.</li>
<li><strong>Effects</strong>:<ul>
<li>Degrades the quality of real-time applications like VoIP or video streaming.</li>
<li>Increases retransmissions, causing further delays and congestion.</li>
</ul>
</li>
<li><strong>Mitigation Techniques</strong>:<ul>
<li>Implementing retransmission protocols (e.g., TCP).</li>
<li>Using redundant packet encoding to recover lost data.</li>
</ul>
</li>
</ul>
<h4 id="1834-congestion-control"><strong>18.3.4 Congestion Control</strong></h4>
<ul>
<li><strong>Definition</strong>: Strategies to prevent and manage excessive packet buildup in the network.</li>
<li><strong>Techniques</strong>:<ol>
<li><strong>Traffic Shaping</strong>:<ul>
<li>Regulates the flow of data entering the network to prevent sudden bursts of traffic.</li>
<li>Example: Token Bucket and Leaky Bucket algorithms.</li>
</ul>
</li>
<li><strong>Packet Scheduling</strong>:<ul>
<li>Prioritizes certain packets based on their importance or type.</li>
<li>Example: First-Come-First-Serve (FCFS) and Priority Scheduling.</li>
</ul>
</li>
<li><strong>Retransmission Strategies</strong>:<ul>
<li>Automatically resends lost or corrupted packets.</li>
<li>Includes mechanisms like Automatic Repeat Request (ARQ).</li>
</ul>
</li>
</ol>
</li>
</ul>
<hr>
<h3 id="184-ipv4-addresses"><strong>18.4 IPv4 ADDRESSES</strong></h3>
<p>IPv4 addresses are a fundamental aspect of the network layer, ensuring that devices can be uniquely identified for communication.</p><h4 id="1841-address-space"><strong>18.4.1 Address Space</strong></h4>
<ul>
<li><strong>32-Bit Addressing</strong>: IPv4 uses a 32-bit structure, allowing for (2^{32}) unique addresses, approximately 4.3 billion.</li>
<li><strong>Depletion</strong>: Due to the rapid growth of devices, the IPv4 address space is nearly exhausted, leading to the adoption of solutions like NAT and IPv6.</li>
</ul>
<h4 id="1842-classful-addressing"><strong>18.4.2 Classful Addressing</strong></h4>
<ul>
<li>IPv4 originally divided its address space into five classes, identified by the first few bits of the address:<ul>
<li><strong>Class A</strong>: <ul>
<li>Range: (0.0.0.0) to (127.255.255.255).</li>
<li>Large networks with up to (2^{24}) hosts.</li>
</ul>
</li>
<li><strong>Class B</strong>:<ul>
<li>Range: (128.0.0.0) to (191.255.255.255).</li>
<li>Medium-sized networks with up to (2^{16}) hosts.</li>
</ul>
</li>
<li><strong>Class C</strong>:<ul>
<li>Range: (192.0.0.0) to (223.255.255.255).</li>
<li>Small networks with up to (2^{8}) hosts.</li>
</ul>
</li>
<li><strong>Class D</strong>:<ul>
<li>Range: (224.0.0.0) to (239.255.255.255).</li>
<li>Reserved for multicast communication.</li>
</ul>
</li>
<li><strong>Class E</strong>:<ul>
<li>Range: (240.0.0.0) to (255.255.255.255).</li>
<li>Reserved for experimental use.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="1843-classless-addressing"><strong>18.4.3 Classless Addressing</strong></h4>
<ul>
<li><strong>CIDR (Classless Inter-Domain Routing)</strong>:<ul>
<li>Eliminates rigid address classes, allowing for flexible allocation of IP addresses.</li>
<li>Uses <strong>prefix notation</strong> (e.g., (192.168.1.0/24)), where the “/24” indicates the number of bits in the network prefix.</li>
</ul>
</li>
<li><strong>Variable-Length Subnet Masking (VLSM)</strong>:<ul>
<li>Divides an IP address into subnets of different sizes.</li>
<li>Helps optimize address utilization and reduce wastage.</li>
</ul>
</li>
</ul>
<h4 id="1844-dynamic-host-configuration-protocol-dhcp"><strong>18.4.4 Dynamic Host Configuration Protocol (DHCP)</strong></h4>
<ul>
<li><strong>Purpose</strong>:<ul>
<li>Automates the assignment of IP addresses, subnet masks, gateways, and DNS settings.</li>
</ul>
</li>
<li><strong>Advantages</strong>:<ul>
<li>Reduces manual configuration errors.</li>
<li>Allows for reusing IP addresses when devices leave the network.</li>
</ul>
</li>
<li><strong>Process</strong>:<ul>
<li>A device sends a <strong>DHCP Discovery</strong> request.</li>
<li>The server responds with a <strong>DHCP Offer</strong> containing configuration details.</li>
<li>The device accepts via a <strong>DHCP Request</strong>, and the server confirms with a <strong>DHCP Acknowledgment</strong>.</li>
</ul>
</li>
</ul>
<h4 id="1845-network-address-translation-nat"><strong>18.4.5 Network Address Translation (NAT)</strong></h4>
<ul>
<li><strong>Purpose</strong>:<ul>
<li>Allows multiple devices on a private network to share a single public IP address.</li>
<li>Conserves the limited IPv4 address space.</li>
</ul>
</li>
<li><strong>Types</strong>:<ul>
<li><strong>Static NAT</strong>: Maps one private IP to one public IP.</li>
<li><strong>Dynamic NAT</strong>: Maps private IPs to available public IPs from a pool.</li>
<li><strong>Port Address Translation (PAT)</strong>: Maps multiple private IPs to a single public IP using unique port numbers.</li>
</ul>
</li>
<li><strong>Advantages</strong>:<ul>
<li>Enhances security by hiding internal network structure.</li>
<li>Reduces the demand for public IP addresses.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="185-forwarding-of-ip-packets"><strong>18.5 FORWARDING OF IP PACKETS</strong></h3>
<p>Forwarding is the mechanism by which routers move packets from their source to the correct destination.</p><h4 id="1851-forwarding-based-on-destination-address"><strong>18.5.1 Forwarding Based on Destination Address</strong></h4>
<ul>
<li><strong>Process</strong>:<ol>
<li>The router examines the destination IP address in the packet header.</li>
<li>It consults its <strong>routing table</strong> to determine the next hop.</li>
<li>The packet is forwarded to the next router or the final destination.</li>
</ol>
</li>
<li><strong>Routing Table Entries</strong>:<ul>
<li><strong>Destination Network</strong>: Identifies the target subnet.</li>
<li><strong>Next Hop</strong>: The IP address of the next router.</li>
<li><strong>Metric</strong>: A value representing the cost or distance to the destination.</li>
</ul>
</li>
</ul>
<h4 id="1852-forwarding-based-on-label"><strong>18.5.2 Forwarding Based on Label</strong></h4>
<ul>
<li><strong>Label-Based Forwarding</strong>:<ul>
<li>Utilized in <strong>Multiprotocol Label Switching (MPLS)</strong>.</li>
<li>Packets are assigned a <strong>label</strong> at the ingress router.</li>
<li>Intermediate routers use labels, not IP addresses, for forwarding decisions.</li>
</ul>
</li>
<li><strong>Advantages</strong>:<ul>
<li>Faster forwarding as label lookups are simpler than IP-based routing.</li>
<li>Supports traffic engineering, allowing for efficient use of network resources.</li>
</ul>
</li>
</ul>
<h4 id="1853-routers-as-packet-switches"><strong>18.5.3 Routers as Packet Switches</strong></h4>
<ul>
<li><strong>Functionality</strong>:<ul>
<li>Routers act as intelligent devices in packet-switched networks.</li>
<li>They handle:<ol>
<li>Receiving packets from the input interface.</li>
<li>Analyzing headers to determine the next hop.</li>
<li>Forwarding packets via the appropriate output interface.</li>
</ol>
</li>
</ul>
</li>
<li><strong>Key Roles</strong>:<ul>
<li><strong>Packet Inspection</strong>: Examines headers for routing and QoS decisions.</li>
<li><strong>Routing Table Maintenance</strong>: Updates routes dynamically using protocols like OSPF or BGP.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="summary-of-key-concepts"><strong>Summary of Key Concepts</strong></h3>
<ul>
<li><strong>Packet Switching</strong>: Core mechanism for efficient data transfer.</li>
<li><strong>Routing and Forwarding</strong>: Ensure packets traverse networks to reach their destination.</li>
<li><strong>IP Addressing</strong>: Vital for device identification and communication, with techniques like CIDR, DHCP, and NAT enhancing efficiency.</li>
<li><strong>Performance Metrics</strong>: Delay, throughput, and congestion control are essential for optimizing communication.</li>
<li><strong>DHCP and NAT</strong>: Critical protocols for managing IP address allocation and conservation.</li>
</ul>

            ]]>
        </content>
    </entry>
</feed>
